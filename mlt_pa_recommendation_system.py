# -*- coding: utf-8 -*-
"""MLT_PA_Recommendation_System.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/148RcxXkO_Vq2fmxQZ7Ut0XBWplR30Q0C

# Movie Recommendation System - *Content Based Filtering & Collaborative Filtering*

## Data Understanding

### Menyiapkan Library
"""

import zipfile
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import EarlyStopping

"""### Menyiapakn Dataset

- Instalasi Paket Kaggle menggunakan perintah `!pip install kaggle`. Perintah ini akan mengunduh dan menginstal paket Kaggle dari Python Package Index (PyPI).
"""

!pip install kaggle

"""- Mengunggah token Kaggle API ke sesi Colab untuk mengakses dataset dan sumber daya Kaggle melalui Google Colab."""

from google.colab import files
files.upload()

"""- Konfigurasi Kaggle API"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

"""- Mengunduh dataset dari Kaggle"""

!kaggle datasets download -d nicoletacilibiu/movies-and-ratings-for-recommendation-system

"""- Melakukan Ekstraksi File zip"""

local_zip = '/content/movies-and-ratings-for-recommendation-system.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

"""- Membaca File & Menampilkan Jumlah Data Unik"""

movies = pd.read_csv('/content/movies.csv')
ratings = pd.read_csv('/content/ratings.csv')

print('Jumlah data movies: ', len(movies['movieId'].unique()))
print('Jumlah data ratings: ', len(ratings['movieId'].unique()))

"""### Univariate Exploratory Data Analysis

#### Eksplorasi Variabel

- Eksplorasi Variabel menggunakan fungsi `movies.info()` pada Variabel Movies.
"""

movies.info()

"""- Eksplorasi Variabel menggunakan fungsi `ratings.info()` pada Variabel Ratings."""

ratings.info()

"""- Menampilkan Data Movies menggunakan fungsi `movies.head()`."""

movies.head()

"""- Menampilkan Data Ratings menggunakan fungsi `ratings.head()`."""

ratings.head()

"""- Mendeskripsikan fitur ratings menggunakan fungsi `ratings.describe()`."""

ratings.describe()

"""- Mencetak Jumlah Data Ratings menggunakan Fungsi `len()`."""

print('Jumlah userID: ', len(ratings.userId.unique()))
print('Jumlah movieId: ', len(ratings.movieId.unique()))
print('Jumlah data rating: ', len(ratings))

"""## Data Preparation

- Menambahkan Kolom `year_of_release` pada Data Movies
"""

movies['year_of_release'] = movies.title.str.extract('([0-9]{4})')
movies.head()

"""- Memisahkan Judul Film dari Tahun Rilis Menggunakan metode `split()`."""

movies['title'] = movies['title'].astype(str)
movies['title'] = movies['title'].str.split(pat='(', n=1).str[0].str.strip()
movies.head()

"""- Memeriksa Nilai pada kolom rating"""

ratings.rating.unique()

"""Rupanya, kolom ratings menunjukkan sebaran data yang tidak normal, di mana data rating memiliki skala 0.5 sampai 5 dengan perbedaan 0.5 pada setiap skala. Untuk konsistensi, akan dilakukan pembulatan sehingga rating memiliki rentang 1 hingga 5.

- Membulatkan nilai pada kolom 'rating' dengan menggunakan fungsi `np.ceil`.
"""

ratings['rating'] = ratings['rating'].apply(np.ceil)

"""- Periksa Kembali Nilai di kolom 'rating' menggunakan fungsi `ratings.rating.unique()`."""

ratings.rating.unique()

"""- Mengubah format waktu pada kolom 'timestamp' dengan menggunakan fungsi `pd.to_datetime`."""

ratings.timestamp = pd.to_datetime(ratings['timestamp'], unit='s')
ratings.head()

"""Sementara ini, frame data rating pengguna tampaknya sudah cukup baik.

- Menggabungkan Data Movies dan Ratings berdasarkan 'movieId' menggunakan fungsi `merge()`.
"""

df = pd.merge(movies, ratings, on='movieId', how='left')
df

"""- Mendeteksi `missing value` dengan fungsi isnull()"""

df.isnull().sum()

"""terdapat missing value pada kolom `year_of_release`, `userId`, `rating`, dan `timestamp`.

- Menghapus `missing value` dengan fungsi dropna()
"""

df_clean = df.dropna()

"""- Mengecek Kembali `missing value` pada DataFrame."""

df_clean.isnull().sum()

"""Sekarang DataFrame sudah bersih dan tidak ada `missing value`.

- Mengurutkan DataFrame berdasarkan Kolom 'movieId'
"""

df_fix = df_clean.sort_values('movieId', ascending=True)
df_fix

"""- Menampilkan Jumlah Data Unik pada Kolom 'movieId'"""

len(df_fix.movieId.unique())

"""- Menampilkan Nilai Unik pada Kolom *genres*"""

df_fix.genres.unique()

"""- Mengecek genre movies `(no genres listed)`"""

df_fix[df_fix['genres']=='(no genres listed)']

"""Ternyata banyak film yang tidak memiliki Genre, untuk itu perlu menghapus baris yang tidak memiliki Genre `(no genres listed)`."""

df_fix = df_fix[(df_fix.genres != '(no genres listed)')]

"""- Membuat variabel preparation yang berisi dataframe `df_fix` kemudian mengurutkan berdasarkan `movieId`"""

preparation = df_fix
preparation.sort_values('movieId')

"""- Menghapus Duplikat Berdasarkan Kolom 'movieId' dan 'title' pada DataFrame Preparation"""

preparation = preparation.drop_duplicates('movieId')
preparation = preparation.drop_duplicates('title')
preparation

"""- Mengganti Nilai pada Kolom 'genres' dalam DataFrame Preparation dengan Nilai 'Sci-Fi' diganti dengan 'Scifi' menggunakan `regex`"""

preparation = preparation.replace(to_replace ='[nS]ci-Fi', value = 'Scifi', regex = True)
preparation.head()

"""Mengonversi Data *Series* menjadi *List* menggunakan fungsi `tolist()` dan mencetak jumlah datanya."""

movie_id = preparation['movieId'].tolist()
movie_title = preparation['title'].tolist()
movie_genre = preparation['genres'].tolist()

print(len(movie_id))
print(len(movie_title))
print(len(movie_genre))

"""- Membuat dictionary untuk data `movie_id`, `movie_title`, dan `movie_genre` dengan nama `df_movies`."""

df_movies = pd.DataFrame({
    'id': movie_id,
    'judul': movie_title,
    'genre': movie_genre
})
df_movies

"""## Model Development

### Content Based Filtering

- Menampilkan Sampel Acak dari DataFrame 'df_movies'
"""

data = df_movies
data.sample(5)

"""#### TF-IDF Vectorizer

- Inisialisasi dan Pemrosesan TfidfVectorizer pada Data Genre
"""

tf = TfidfVectorizer()
tf.fit(data['genre'])
tf.get_feature_names_out()

"""- Transformasi TF-IDF pada Data Genre dan Memeriksa Ukuran Matrix"""

tfidf_matrix = tf.fit_transform(data['genre'])
tfidf_matrix.shape

"""- Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi `todense()`."""

tfidf_matrix.todense()

"""- Membuat dataframe untuk melihat tf-idf matrix"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.judul
).sample(20, axis=1).sample(10, axis=0)

"""#### Cosine Similarity

- Menghitung cosine similarity pada matrix tf-idf
"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""- Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa Judul Film dan Melihat similarity matrix pada setiap Movie."""

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['judul'], columns=data['judul'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""#### Get Recommendations"""

def movie_recommendations(judul, similarity_data=cosine_sim_df, items=data[['judul', 'genre']], k=5):

    """
    Rekomendasi Movies berdasarkan kemiripan dataframe

    Parameter:
    ---
    judul : tipe data string (str)
                Nama Movies (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan Movies sebagai
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---

    Pada index ini, kita mengambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).

    """

    index = similarity_data.loc[:,judul].to_numpy().argpartition(
        range(-1, -k, -1))

    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    closest = closest.drop(judul, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""Fungsi `movie_recommendations` menggunakan konsep argpartition untuk mendapatkan indeks dengan nilai similarity terbesar pada baris yang sesuai dengan film yang dicari (judul). Selanjutnya, film-film dengan similarity terbesar diambil sebagai rekomendasi, dan judul film yang dicari dihapus dari daftar rekomendasi agar tidak muncul sebagai rekomendasi itu sendiri. Hasil rekomendasi ini kemudian diubah ke dalam DataFrame yang berisi judul dan genre film-film tersebut, dan hanya diambil sejumlah k rekomendasi teratas.

- Mendapatkan Informasi Judul "Bill & Ted's Bogus Journey" dari DataFrame 'data' Menggunakan fungsi `eq()` untuk mencari baris yang memiliki Judul dalam DataFrame 'data'
"""

data[data.judul.eq("Bill & Ted's Bogus Journey")]

"""- Mendapatkan Rekomendasi Movies"""

movie_recommendations("Bill & Ted's Bogus Journey")

"""### Collaborative Filtering

- Membaca Dataset
"""

df = preparation
df

"""#### Data Preparation

- Melakukan encoding pada kolom `userId`.
"""

user_ids = df['userId'].unique().tolist()
print('list userID: ', user_ids)

user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userId : ', user_to_user_encoded)

user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userId: ', user_encoded_to_user)

"""- Melakukan encoding pada kolom `movieId`."""

movie_ids = df['movieId'].unique().tolist()
print('list movieId: ', movie_ids)

movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}
print('encoded movieId : ', movie_to_movie_encoded)

movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}
print('encoded angka ke movieId: ', movie_encoded_to_movie)

"""Kedua kode diatas bertujuan untuk menciptakan mapping antara `userId` dan `movieId` dengan angka-angka unik sebagai representasi encoded-nya. Hal ini umumnya diperlukan dalam proses pengolahan data dan pembuatan model machine learning, di mana beberapa algoritma memerlukan input berupa nilai numerik.

- melakukan mapping kolom `userId` dan `movieId` ke dalam DataFrame `df` dengan menggunakan hasil encoding yang telah dibuat sebelumnya.
"""

df['user'] = df['userId'].map(user_to_user_encoded)
df['movie'] = df['movieId'].map(movie_to_movie_encoded)

"""Dengan penambahan kolom 'user' dan 'movie' ini, telah berhasil menggantikan nilai 'userId' dan 'movieId' dengan representasi angka yang lebih efisien dan memudahkan proses selanjutnya dalam pembangunan model.

- Menyiapkan data pada model sistem rekomendasi. Dalam proses ini, jumlah pengguna (users) dan jumlah film (movies) dihitung, serta rating yang awalnya disimpan sebagai nilai integer diubah menjadi nilai float32. Selanjutnya, dihitung nilai minimum (min_rating) dan maksimum (max_rating) dari rating yang digunakan dalam dataset. Proses ini memberikan pemahaman awal tentang distribusi rating dalam dataset, dan nilai minimum serta maksimumnya. Informasi ini dapat berguna dalam normalisasi atau skala rating pada tahap berikutnya dalam pengembangan model rekomendasi.
"""

num_users = len(user_to_user_encoded)
print(num_users)

num_movie = len(movie_encoded_to_movie)
print(num_movie)

df['rating'] = df['rating'].values.astype(np.float32)

min_rating = min(df['rating'])

max_rating = max(df['rating'])

print('Number of User: {}, Number of Movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""Dengan langkah-langkah ini, memastikan bahwa data telah siap untuk digunakan dalam proses selanjutnya, dan kita memiliki pemahaman yang lebih baik tentang sifat data yang akan diolah.

#### Membagi Data untuk Training dan Validasi

- Mengacak Baris DataFrame
"""

df = df.sample(frac=1, random_state=42)
df

"""- Pembuatan variabel x dan y dan Membagi menjadi 80% data train dan 20% data validasi untuk melatih model."""

x = df[['user', 'movie']].values

y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""Langkah-langkah ini, untuk menyiapkan data input dan output untuk melatih model rekomendasi. Variabel x berisi informasi user dan movie, sedangkan variabel y berisi nilai rating yang telah dinormalisasi. Data tersebut telah dibagi menjadi data train dan data validation untuk proses pelatihan model.

## Proses Training

- Mendefinisikan kelas `RecommenderNet` sebagai model rekomendasi menggunakan TensorFlow dan Keras.
"""

class RecommenderNet(tf.keras.Model):

    def __init__(self, num_users, num_movie, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_movie = num_movie
        self.embedding_size = embedding_size

        self.user_embedding = layers.Embedding(
            num_users,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1)

        self.movie_embedding = layers.Embedding(
            num_movie,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.movie_bias = layers.Embedding(num_movie, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])

        movie_vector = self.movie_embedding(inputs[:, 1])
        movie_bias = self.movie_bias(inputs[:, 1])

        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)

        x = dot_user_movie + user_bias + movie_bias

        return tf.nn.sigmoid(x)

"""Selanjutnya kelas `RecommenderNet` dapat digunakan sebagai model untuk melakukan prediksi rekomendasi berdasarkan vektor embedding dari user dan movie.

- Melakukan inisialisasi dan kompilasi model `RecommenderNet` menggunakan TensorFlow dan Keras.
"""

model = RecommenderNet(num_users, num_movie, 50)

model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""- Membuat Callback EarlyStopping."""

early_stopping_callback = EarlyStopping(
    patience=5,
    restore_best_weights=True,
    monitor='val_root_mean_squared_error',
    mode='min'
)

"""Dengan penggunaan callback EarlyStopping, pelatihan akan berhenti jika tidak ada peningkatan yang signifikan pada metrik validasi (RMSE pada data validasi) selama beberapa epoch, sesuai dengan parameter patience.

- Memulai Training
"""

history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=32,
    epochs=100,
    validation_data=(x_val, y_val),
    callbacks=[early_stopping_callback]
)

"""## Evaluation

- Evaluasi Model pada Data Uji & Data Latih
"""

test_loss, test_rmse = model.evaluate(x, y)
val_loss, val_rmse = model.evaluate(x_val, y_val)

print(f'Test Loss: {test_loss}, Test RMSE: {test_rmse}')
print(f'Validation Loss: {val_loss}, Validation RMSE: {val_rmse}')

"""Setelah menyelesaikan pelatihan model Collaborative Filtering, hasil evaluasi pada data uji menunjukkan kinerja yang memuaskan. Fungsi kerugian (Test Loss) sebesar 0.5367 mencerminkan seberapa baik model memberikan prediksi terhadap nilai sebenarnya, dengan nilai yang relatif rendah menandakan tingkat akurasi yang baik. Selain itu, Root Mean Squared Error (Test RMSE) sebesar 0.1368 mengindikasikan deviasi rata-rata antara prediksi dan nilai sebenarnya, dengan nilai yang rendah menunjukkan tingkat akurasi yang tinggi dalam memprediksi preferensi pengguna terhadap item.

Selama pelatihan, model juga dievaluasi pada data validasi, di mana fungsi kerugian (Validation Loss) sebesar 0.6496 dan Root Mean Squared Error (Validation RMSE) sebesar 0.2619. Evaluasi pada data validasi memberikan gambaran tambahan tentang kinerja model di luar data uji dan membantu memastikan bahwa model tidak mengalami overfitting yang signifikan.

- Visualisasi Metrik Evaluasi
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Model Metrics')
plt.ylabel('RMSE')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""Metrik Evaluasi menunjukkan bahwa model memiliki performa yang baik dan model konvergen pada epochs sekitar 98. Dari proses ini, kita memperoleh nilai error akhir sebesar sekitar 0.0737 dan error pada data validasi sebesar 0.2619. Nilai tersebut dapat digunakan untuk membuat sistem rekomendasi.

- Menyimapan Model Rekomendasi & Memuat model dari format SavedModel.
"""

model.save('my_recommendation_model', save_format='tf')
loaded_model = tf.keras.models.load_model('my_recommendation_model')

"""## Get Movie Recommendations

- Membaca Data
"""

movie_df = preparation

"""- Berikut kode untuk mengambil sampel pengguna (user) secara acak dan mendapatkan film-film yang telah dikunjungi oleh pengguna tersebut. Selanjutnya, film-film yang belum dikunjungi oleh pengguna diidentifikasi menggunakan operator `bitwise ~` dan disimpan dalam variabel `movie_not_visited`. Proses ini melibatkan pemfilteran data film dengan menggunakan movieId yang tidak termasuk dalam film-film yang telah dikunjungi oleh pengguna. Setelah itu, movieId yang belum dikunjungi dikonversi menjadi list dan diubah menjadi bentuk yang sesuai untuk digunakan dalam model rekomendasi. Terakhir, sebuah array yang berisi pengguna dan film-film yang belum dikunjungi tersebut dibentuk untuk digunakan dalam proses mendapatkan rekomendasi dari model."""

user_id = df.userId.sample(1).iloc[0]
movie_visited_by_user = df[df.userId == user_id]

movie_not_visited = movie_df[~movie_df['movieId'].isin(movie_visited_by_user.movieId.values)]['movieId']
movie_not_visited = list(
    set(movie_not_visited)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movie_not_visited = [[movie_to_movie_encoded.get(x)] for x in movie_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_visited), movie_not_visited)
)

"""- Selanjutnya kita akan membuat kode untuk mendapatkan prediksi rating dari model untuk film-film yang belum dikunjungi oleh pengguna. Proses ini melibatkan penggunaan model untuk memprediksi rating untuk film-film yang belum dikunjungi, dan kemudian memilih 10 film dengan rating tertinggi sebagai rekomendasi. Hasil rekomendasi ini kemudian dicetak, termasuk film-film dengan rating tertinggi yang telah dikunjungi oleh pengguna untuk memberikan konteks lebih lanjut. Proses ini memungkinkan pengguna melihat rekomendasi film yang dapat menarik minat mereka berdasarkan model rekomendasi yang telah dibangun.






"""

ratings = model.predict(user_movie_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_visited[x][0]) for x in top_ratings_indices
]

print('Menampilkan Rekomendasi untuk Pengguna (User): {}'.format(user_id))
print('===' * 9)
print('Film dengan Rating Tinggi dari Pengguna (User)')
print('----' * 8)

top_movie_user = (
    movie_visited_by_user.sort_values(
        by='rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movie_df_rows = movie_df[movie_df['movieId'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.title, ':', row.genres)

print('----' * 8)
print('10 Rekomendasi Film Teratas')
print('----' * 8)

recommended_movie = movie_df[movie_df['movieId'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.title, ':', row.genres)